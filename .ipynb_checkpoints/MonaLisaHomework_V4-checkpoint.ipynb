{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4\n",
    "\n",
    "SYS 6018: Machine Learning\n",
    "\n",
    "Caitlin Dreisbach (CND2y)\n",
    "\n",
    "Elizabeth Homan Harrsion (EIH2NN)\n",
    "\n",
    "Morgan Wall (MKW5CK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkw5c\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Functions:\n",
    "def conv2d(x, W):\n",
    "    \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x,name):\n",
    "    \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME',name=name)\n",
    " \n",
    "\n",
    "def weight_variable(shape,varname):\n",
    "    \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=varname)\n",
    "\n",
    "\n",
    "def bias_variable(shape,varname):\n",
    "    \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ConvNet\n",
    "def deepnn(x):\n",
    "    # x is 64x64x3\n",
    "    \n",
    "    # First Conv, Relu and 2x2 max-pooling layers\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([5, 5, 3, 16],'conv_w')\n",
    "        b_conv1 = bias_variable([16],'conv_b')\n",
    "        h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1,name='h_conv_op')\n",
    "        h_pool1 = max_pool_2x2(h_conv1,'h_pool_op')\n",
    "    # output: 32x32x16\n",
    " \n",
    "    # Second Conv, Relu and 2x2 max-pooling layers\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = weight_variable([5, 5, 16, 16],'conv_w')\n",
    "        b_conv2 = bias_variable([16],'conv_b')\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2,name='h_conv_op')\n",
    "        h_pool2 = max_pool_2x2(h_conv2,'h_pool_op')\n",
    "    # output: 16x16x16\n",
    "\n",
    "    # Third Conv, Relu and 2x2 max-pooling layers\n",
    "    with tf.name_scope('conv3'):\n",
    "        W_conv3 = weight_variable([5, 5, 16, 32],'conv_w')\n",
    "        b_conv3 = bias_variable([32],'conv_b')\n",
    "        h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3,name='h_conv_op')\n",
    "        h_pool3 = max_pool_2x2(h_conv3,'h_pool_op')\n",
    "    # output: 8x8x32\n",
    "\n",
    "    # First Fully Connected Layer\n",
    "    with tf.name_scope('fc'):\n",
    "        # Flatten output from previous layer\n",
    "        h_pool3_flat = tf.reshape(h_pool3, [-1, 8*8*32])\n",
    "        # Fully connected + Relu\n",
    "        # input: flat (8x8x32) = 1x2048\n",
    "        W_fc1 = weight_variable([8 * 8* 32, 1024],'fc_w')\n",
    "        b_fc1 = bias_variable([1024],'fc_b')\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "    # output: 1x1024\n",
    "    \n",
    "    # Dropout\n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    # Output Softmax Layer: Map the 1024 features to 2 classes, one for each class type\n",
    "    with tf.name_scope('sm'):\n",
    "        W_sm = weight_variable([1024, 2],'sm_w')\n",
    "        b_sm = bias_variable([2],'sm_b')\n",
    "        y_conv_out = tf.add(tf.matmul(h_fc1_drop, W_sm), b_sm, name=\"y_conv_op\")\n",
    " \n",
    "    return y_conv_out,keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra functions:\n",
    "# DataSet class to handle images \n",
    "class DataSet(object):\n",
    "    def __init__(self, images, labels):\n",
    "        self._num_examples = len(images)\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._epochs_done = 0\n",
    "        self._index_in_epoch = 0\n",
    "        np.random.seed(123456)\n",
    "        # Shuffle the data\n",
    "        perm = np.arange(self._num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        self._images = self._images[perm]\n",
    "        self._labels = self._labels[perm]\n",
    "        random.seed(123456)\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "    @property\n",
    "    def epochs_done(self):\n",
    "        return self._epochs_done\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # After each epoch we update this\n",
    "            self._epochs_done += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm] \n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "    \n",
    "        return self._images[start:end], self._labels[start:end]\n",
    "\n",
    "# read images from a directory\n",
    "def read_images(path,images,labels,class_num,class_index):\n",
    "    files = glob.glob(os.path.join(path, '*g'))\n",
    "    for fl in files:\n",
    "        image = cv2.imread(fl)\n",
    "        image = image.astype(np.float32)\n",
    "        image = np.multiply(image, 1.0 / 255.0)\n",
    "        images.append(image)\n",
    "        label = np.zeros(class_num)\n",
    "        label[class_index] = 1.0\n",
    "        labels.append(label)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in image data from sub-directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_from_disk(input_queue):\n",
    "    \"\"\"Consumes a single filename and label as a ' '-delimited string.\n",
    "    Args:\n",
    "      filename_and_label_tensor: A scalar string tensor.\n",
    "    Returns:\n",
    "      Two tensors: the decoded image, and the string label.\n",
    "    \"\"\"\n",
    "    label = input_queue[1]\n",
    "    file_contents = tf.read_file(input_queue[0])\n",
    "    example = tf.image.decode_png(file_contents, channels=3)\n",
    "    return example, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path1 = \"/Users/caitdreisbach/Downloads/imagesML/train\"\n",
    "\n",
    "#path1 = \"/Users/eihoman/Desktop/DSI/Machine Learning/hw/Assignment 4/images/train\"\n",
    "\n",
    "path1 = \"C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\mona_lisa_pics\\\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\anger', 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\contempt', 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\disgust', 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\fear', 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\happiness', 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\neutral', 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\sadness', 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\surprise']\n"
     ]
    }
   ],
   "source": [
    "#get labeled directories into a list\n",
    "directory_list = list()\n",
    "for root, dirs, files in os.walk(path1, topdown=False):\n",
    "    for name in dirs:\n",
    "        directory_list.append(os.path.join(root, name))\n",
    "\n",
    "print(directory_list[0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\anger', 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\anger', 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\anger', 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\anger']\n"
     ]
    }
   ],
   "source": [
    "#label_list = []\n",
    "#for item in directory_list:\n",
    "#    label_list.append(os.path.dirname(item))\n",
    "#print(label_list[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'contempt',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'happiness',\n",
       " 'neutral',\n",
       " 'sadness',\n",
       " 'surprise']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove path prior to file name\n",
    "import ntpath\n",
    "ntpath.basename(path1)\n",
    "\n",
    "def path_leaf(path):\n",
    "    head, tail = ntpath.split(path)\n",
    "    return tail or ntpath.basename(head)\n",
    "\n",
    "#paths = ['/Users/caitdreisbach/Downloads/imagesML/train/contempt', \n",
    "#         '/Users/caitdreisbach/Downloads/imagesML/train/fear', \n",
    "#         '/Users/caitdreisbach/Downloads/imagesML/train/surprise', \n",
    "#         '/Users/caitdreisbach/Downloads/imagesML/train/sadness', \n",
    "#         '/Users/caitdreisbach/Downloads/imagesML/train/neutral', \n",
    "#         '/Users/caitdreisbach/Downloads/imagesML/train/happiness', \n",
    "#         '/Users/caitdreisbach/Downloads/imagesML/train/anger', \n",
    "#         '/Users/caitdreisbach/Downloads/imagesML/train/disgust']\n",
    "\n",
    "#paths = ['/Users/eihoman/Desktop/DSI/Machine Learning/hw/Assignment 4/images/train/contempt', \n",
    "#         '/Users/eihoman/Desktop/DSI/Machine Learning/hw/Assignment 4/images/train/fear', \n",
    "#         '/Users/eihoman/Desktop/DSI/Machine Learning/hw/Assignment 4/images/train/surprise', \n",
    "#         '/Users/eihoman/Desktop/DSI/Machine Learning/hw/Assignment 4/images/train/sadness', \n",
    "#         '/Users/eihoman/Desktop/DSI/Machine Learning/hw/Assignment 4/images/train/neutral', \n",
    "#         '/Users/eihoman/Desktop/DSI/Machine Learning/hw/Assignment 4/images/train/happiness', \n",
    "#         '/Users/eihoman/Desktop/DSI/Machine Learning/hw/Assignment 4/images/train/anger', \n",
    "#         '/Users/eihoman/Desktop/DSI/Machine Learning/hw/Assignment 4/images/train/disgust']\n",
    "\n",
    "paths =['C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\anger',\n",
    "        'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\contempt', \n",
    "        'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\disgust',\n",
    "        'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\fear',\n",
    "        'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\happiness', \n",
    "        'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\neutral',\n",
    "        'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\sadness', \n",
    "        'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\surprise']\n",
    "\n",
    "\n",
    "label_classes = [path_leaf(path) for path in directory_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathimage1 = 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\contempt'\n",
    "pathimage2 = 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\fear'\n",
    "pathimage3 = 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\surprise'\n",
    "pathimage4 = 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\sadness' \n",
    "pathimage5 =  'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\neutral' \n",
    "pathimage6 =  'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\happiness'\n",
    "pathimage7 = 'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\anger'\n",
    "pathimage8 =  'C:\\\\Users\\\\mkw5c\\\\Desktop\\\\\\\\mona_lisa_pics\\\\train\\\\disgust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "imagestest = []\n",
    "labelstest = []\n",
    "x = read_images(pathimage1,imagestest,labelstest,1,0)\n",
    "print(len(x[1]))\n",
    "imagestest = []\n",
    "labelstest = []\n",
    "x = read_images(pathimage2,imagestest,labelstest,1,0)\n",
    "print(len(x[1]))\n",
    "imagestest = []\n",
    "labelstest = []\n",
    "x = read_images(pathimage3,imagestest,labelstest,1,0)\n",
    "print(len(x[1]))\n",
    "imagestest = []\n",
    "labelstest = []\n",
    "x = read_images(pathimage4,imagestest,labelstest,1,0)\n",
    "print(len(x[1]))\n",
    "imagestest = []\n",
    "labelstest = []\n",
    "x = read_images(pathimage5,imagestest,labelstest,1,0)\n",
    "print(len(x[1]))\n",
    "imagestest = []\n",
    "labelstest = []\n",
    "x = read_images(pathimage6,imagestest,labelstest,1,0)\n",
    "print(len(x[1]))\n",
    "imagestest = []\n",
    "labelstest = []\n",
    "x = read_images(pathimage7,imagestest,labelstest,1,0)\n",
    "print(len(x[1]))\n",
    "imagestest = []\n",
    "labelstest = []\n",
    "x = read_images(pathimage8,imagestest,labelstest,1,0)\n",
    "print(len(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'anger', 'anger', ..., 'surprise', 'surprise', 'surprise'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images\n",
      "Finished reading images\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-35a2767c6b8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m181\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Contempt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1edc7a55e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load images\n",
    "images = []\n",
    "#labels = []\n",
    "\n",
    "print('Reading images')\n",
    "images=read_images(path1,images,labels,8,0)\n",
    "#images,labels=read_images(pathimage2,images,labels,8,1)\n",
    "#images,labels=read_images(pathimage3,images,labels,8,2)\n",
    "#images,labels=read_images(pathimage4,images,labels,8,3)\n",
    "#images,labels=read_images(pathimage5,images,labels,8,4)\n",
    "#images,labels=read_images(pathimage6,images,labels,8,5)\n",
    "#images,labels=read_images(pathimage7,images,labels,8,6)\n",
    "#images,labels=read_images(pathimage8,images,labels,8,7)\n",
    "print('Finished reading images') \n",
    "\n",
    "images = np.array(images)\n",
    "#labels = np.array(labels)\n",
    "\n",
    "# Create dataset\n",
    "train = DataSet(images, labels)\n",
    "\n",
    "# parameters\n",
    "model_dir=\"model_Mona_Lisa\"\n",
    "max_itr=1000\n",
    "image_size=240\n",
    "\n",
    "# Inspect Data: Show first image of each type\n",
    "fig = plt.figure(figsize=(20, 20)) \n",
    "\n",
    "ax = fig.add_subplot(181)\n",
    "plt.imshow(images[0])\n",
    "ax.set_title('Contempt')  \n",
    "\n",
    "ax = fig.add_subplot(182)\n",
    "plt.imshow(images[120])\n",
    "ax.set_title('Fear')\n",
    "\n",
    "ax = fig.add_subplot(183)\n",
    "plt.imshow(images[245])\n",
    "ax.set_title('Surprise')\n",
    "\n",
    "ax = fig.add_subplot(184)\n",
    "plt.imshow(images[440])\n",
    "ax.set_title('Sadness')\n",
    "\n",
    "ax = fig.add_subplot(185)\n",
    "plt.imshow(images[575])\n",
    "ax.set_title('Neutral')\n",
    "\n",
    "ax = fig.add_subplot(186)\n",
    "plt.imshow(images[1202])\n",
    "ax.set_title('Happiness')\n",
    "\n",
    "ax = fig.add_subplot(187)\n",
    "plt.imshow(images[1350])\n",
    "ax.set_title('Anger')\n",
    "\n",
    "ax = fig.add_subplot(188)\n",
    "plt.imshow(images[1490])\n",
    "ax.set_title('Disgust')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create computational graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******** Cell - 1 ***********\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():   \n",
    "    # Create the computational graph:\n",
    "    # Placeholders:\n",
    "    x = tf.placeholder(tf.float32, [None, image_size,image_size,3],name=\"x\")\n",
    "    y = tf.placeholder(tf.float32, [None, 8],name=\"y\")\n",
    "        \n",
    "    # Build the graph for the deep net\n",
    "    y_conv_out,keep_prob = deepnn(x)\n",
    "    \n",
    "    # Add loss, accuracy and optimization\n",
    "    probs=tf.nn.softmax(logits=y_conv_out, name=\"probs_op\")\n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=y_conv_out)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    with tf.name_scope('adam_optimizer'):\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv_out, 1), tf.argmax(y, 1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction, name=\"acc_op\")\n",
    "        \n",
    "    # Add a saver to save the trained model\n",
    "    saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (32, 8) for Tensor 'y:0', which has shape '(?, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-5135d8b5e902>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_true_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# save final model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   2278\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2279\u001b[0m     \"\"\"\n\u001b[1;32m-> 2280\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2282\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gradient\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5049\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5050\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 5051\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1114\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1116\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1117\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (32, 8) for Tensor 'y:0', which has shape '(?, 2)'"
     ]
    }
   ],
   "source": [
    "# ******** Cell - 2 ***********\n",
    "# Reset graph: useful for multiple runs (e.g., parameter tuning, CV, etc.)\n",
    "tf.reset_default_graph()  \n",
    "# Create session to execute graph\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(max_itr):\n",
    "        # Save a version of the model every 100 iterations\n",
    "        if i>0 and i%100==0:\n",
    "            saver.save(sess, \"./%s/model\"%(model_dir), global_step=i)\n",
    "            \n",
    "        # Get a batch of 32 images    \n",
    "        x_batch, y_true_batch = train.next_batch(32) \n",
    "        \n",
    "        # Get training accuracy on the batch\n",
    "        if i>0 and i % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: x_batch , y: y_true_batch, keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "            \n",
    "        # Train\n",
    "        train_step.run(feed_dict={x: x_batch, y: y_true_batch, keep_prob: 0.5})\n",
    "    \n",
    "    # save final model\n",
    "    save_path = saver.save(sess, \"./%s/model\"%(model_dir), global_step=max_itr)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    # Get training accuracy on all training images\n",
    "    train_accuracy=accuracy.eval(feed_dict={x: images,y: labels, keep_prob: 1.0 })\n",
    "    print (\"Training Accuracy: %10.5f\"%train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testing images\n",
    "test_images = []   \n",
    "test_labels = []   \n",
    "\n",
    "print('Reading testing images')\n",
    "test_images,test_labels=read_images('jellyfish_valid',test_images,test_labels,2,0)\n",
    "test_images,test_labels=read_images('bullfrog_valid',test_images,test_labels,2,1)\n",
    "print('Finished reading testing images') \n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******** Cell - 3 ***********\n",
    "# Test model on testing data\n",
    "with tf.Session() as sess:    \n",
    "    saver = tf.train.import_meta_graph('./%s/model-%s.meta'%(model_dir,max_itr))\n",
    "    saver.restore(sess,tf.train.latest_checkpoint(model_dir))\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    #print([n.name for n in tf.get_default_graph().as_graph_def().node])\n",
    "     \n",
    "    x = graph.get_tensor_by_name(\"x:0\")\n",
    "    y = graph.get_tensor_by_name(\"y:0\")\n",
    "    keep_prob= graph.get_tensor_by_name(\"dropout/keep_prob:0\") \n",
    "    accuracy = graph.get_tensor_by_name(\"accuracy/acc_op:0\")\n",
    "    \n",
    "    acc_val=accuracy.eval(feed_dict={x: test_images,y: test_labels, keep_prob: 1.0 })\n",
    "    \n",
    "    print (\"Testing Accuracy: %10.5f\"%acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (more challenging): Bull Frog VS. Tailed Frog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "print('Reading images')\n",
    "images,labels=read_images('tailed frog_train/images',images,labels,2,0)\n",
    "images,labels=read_images('bullfrog_train/images',images,labels,2,1)\n",
    "print('Finished reading images')\n",
    "\n",
    "# Create dataset\n",
    "train = DataSet(np.array(images), np.array(labels))\n",
    "\n",
    "# parameters\n",
    "model_dir=\"model_bull_tailed_frog\"\n",
    "max_itr=1000\n",
    "image_size=64\n",
    "\n",
    "# Inspect Data: Show first image of each type\n",
    "fig = plt.figure(figsize=(4, 4)) \n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "plt.imshow(images[0])\n",
    "ax.set_title('Tailed Frog')  \n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "plt.imshow(images[501])\n",
    "ax.set_title('Bull Frog')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run Cells 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testing images and test model\n",
    "test_images=[]\n",
    "test_labels=[]\n",
    "print('Reading images')\n",
    "test_images,test_labels=read_images('tailed frog_valid',test_images,test_labels,2,0)\n",
    "test_images,test_labels=read_images('bullfrog_valid',test_images,test_labels,2,1)\n",
    "print('Finished reading images') \n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run Cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to improve our ConvNet model\n",
    "# Approach: Try larger filters, more filters & Train for more iterations\n",
    "max_itr = 3000\n",
    "def deepnn(x):\n",
    "    # x is 64x64x3\n",
    "    \n",
    "    # First Conv, Relu and 2x2 max-pooling layers\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([11, 11, 3, 16],'conv_w')\n",
    "        b_conv1 = bias_variable([16],'conv_b')\n",
    "        h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1,name='h_conv_op')\n",
    "        h_pool1 = max_pool_2x2(h_conv1,'h_pool_op')\n",
    "    # output: 32x32x16\n",
    " \n",
    "    # Second Conv, Relu and 2x2 max-pooling layers\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = weight_variable([11, 11, 16, 32],'conv_w')\n",
    "        b_conv2 = bias_variable([32],'conv_b')\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2,name='h_conv_op')\n",
    "        h_pool2 = max_pool_2x2(h_conv2,'h_pool_op')\n",
    "    # output: 16x16x16\n",
    "\n",
    "    # Third Conv, Relu and 2x2 max-pooling layers\n",
    "    with tf.name_scope('conv3'):\n",
    "        W_conv3 = weight_variable([5, 5, 32, 64],'conv_w')\n",
    "        b_conv3 = bias_variable([64],'conv_b')\n",
    "        h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3,name='h_conv_op')\n",
    "        h_pool3 = max_pool_2x2(h_conv3,'h_pool_op')\n",
    "    # output: 8x8x32\n",
    "\n",
    "    # First Fully Connected Layer\n",
    "    with tf.name_scope('fc'):\n",
    "        # Flatten output from previous layer\n",
    "        h_pool3_flat = tf.reshape(h_pool3, [-1, 8*8*64])\n",
    "        # Fully connected + Relu\n",
    "        # input: flat (8x8x32) = 1x2048\n",
    "        W_fc1 = weight_variable([8 * 8* 64, 1024],'fc_w')\n",
    "        b_fc1 = bias_variable([1024],'fc_b')\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "    # output: 1x1024\n",
    "    \n",
    "    # Dropout\n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    # Output Softmax Layer: Map the 1024 features to 2 classes, one for each class type\n",
    "    with tf.name_scope('sm'):\n",
    "        W_sm = weight_variable([1024, 2],'sm_w')\n",
    "        b_sm = bias_variable([2],'sm_b')\n",
    "        y_conv_out = tf.add(tf.matmul(h_fc1_drop, W_sm), b_sm, name=\"y_conv_op\")\n",
    " \n",
    "    return y_conv_out,keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cells 1, 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet block definition\n",
    "<img src=\"resNetBlock.png\" style=\"width: 800px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Source: https://github.com/tensorflow/models/blob/master/official/resnet/resnet_model.py\n",
    "################################################################################\n",
    "def _building_block_v1(inputs, filters, training, projection_shortcut, strides,\n",
    "                       data_format):\n",
    "  \"\"\"A single block for ResNet v1, without a bottleneck.\n",
    "  Convolution then batch normalization then ReLU as described by:\n",
    "    Deep Residual Learning for Image Recognition\n",
    "    https://arxiv.org/pdf/1512.03385.pdf\n",
    "    by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.\n",
    "  Args:\n",
    "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
    "      [batch, height_in, width_in, channels] depending on data_format.\n",
    "    filters: The number of filters for the convolutions.\n",
    "    training: A Boolean for whether the model is in training or inference\n",
    "      mode. Needed for batch normalization.\n",
    "    projection_shortcut: The function to use for projection shortcuts\n",
    "      (typically a 1x1 convolution when downsampling the input).\n",
    "    strides: The block's stride. If greater than 1, this block will ultimately\n",
    "      downsample the input.\n",
    "    data_format: The input format ('channels_last' or 'channels_first').\n",
    "  Returns:\n",
    "    The output tensor of the block; shape should match inputs.\n",
    "  \"\"\"\n",
    "  shortcut = inputs\n",
    "\n",
    "  if projection_shortcut is not None:\n",
    "    shortcut = projection_shortcut(inputs)\n",
    "    shortcut = batch_norm(inputs=shortcut, training=training,\n",
    "                          data_format=data_format)\n",
    "\n",
    "  inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
    "      data_format=data_format)\n",
    "  inputs = batch_norm(inputs, training, data_format)\n",
    "  inputs = tf.nn.relu(inputs)\n",
    "\n",
    "  inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=filters, kernel_size=3, strides=1,\n",
    "      data_format=data_format)\n",
    "  inputs = batch_norm(inputs, training, data_format)\n",
    "  inputs += shortcut\n",
    "  inputs = tf.nn.relu(inputs)\n",
    "\n",
    "return inputs"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
